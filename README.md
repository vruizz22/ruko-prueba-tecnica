# Prueba T√©cnica Ruklo

## Propuesta de stack y arquitectura

Para abordar esta prueba t√©cnica, he decidido utilizar un stack alineado con el entorno tecnol√≥gico de la empresa y que me permita escalar la soluci√≥n f√°cilmente en un entorno real:

- **Frontend:** Next.js (aunque no es requerido para la prueba, lo considero para una posible extensi√≥n futura y alineaci√≥n con el stack de la empresa).
- **Backend:** Nest.js (TypeScript), por su estructura modular, escalabilidad y soporte para buenas pr√°cticas.
- **Base de datos:** PostgreSQL. Ideal para modelar relaciones y escalar.
- **ORM:** Prisma, por su integraci√≥n con TypeScript y PostgreSQL, y facilidad de uso y migraci√≥n.
- **Infraestructura:** AWS (pensando en escalabilidad futura, aunque para la prueba se ejecuta localmente).
- **Testing:** Jest (integrado en Nest.js).
- **Linting y formato:** ESLint + Prettier.

**Nota:** He optado por usar una base de datos, cargando los datos desde el archivo `ruklo_events_1000.json` para simular un entorno real y facilitar la escalabilidad y consultas eficientes. Esto permite que la soluci√≥n sea m√°s robusta y f√°cil de mantener a largo plazo

---

## üß© Resoluci√≥n de la prueba

### üß† Parte 1

#### 1. Beneficio por visitas seguidas

**Pregunta:** Explica c√≥mo har√≠as para evitar errores si esto se ejecuta sobre muchos eventos (¬øusar√≠as un job, cach√©, base de datos?, ¬øc√≥mo lo validar√≠as?)
**Respuesta:**

Actualmente, la l√≥gica agrupa en memoria todos los eventos por cliente y recorre secuencialmente los eventos de cada cliente para detectar las 5 visitas consecutivas sin recarga. Este enfoque es eficiente para vol√∫menes peque√±os o medianos.

Para escalar y evitar errores con grandes vol√∫menes de eventos, se recomienda:

- Procesar los eventos en lotes (batch) o mediante jobs as√≠ncronos usando colas de tareas (por ejemplo, Bull/Redis) para no saturar la memoria y permitir reintentos controlados.
- O bien, delegar la l√≥gica de detecci√≥n a la base de datos usando una consulta SQL con funciones de ventana (window functions) para identificar las secuencias directamente en el motor, reduciendo la cantidad de datos transferidos y el uso de memoria en Node.js.

Ambas opciones pueden integrarse f√°cilmente a partir de la implementaci√≥n actual, permitiendo mantener la l√≥gica de negocio y mejorar la robustez ante grandes vol√∫menes de datos.

#### 2. Historial de transacciones agrupado

**Pregunta:** Considera c√≥mo ordenar√≠as y devolver√≠as los datos.
**Respuesta:**
Para el historial de transacciones agrupado por semana, se entregan los datos en un json con la siguiente estructura:

```json
[
  {
    "client_id": "client_1",
    "history": [
      {
        "type": "visit",
        "weeks": [
          { "week": "2025-W25", "count": 3 },
          { "week": "2025-W26", "count": 5 }
        ]
      },
      {
        "type": "recharge",
        "weeks": [
          { "week": "2025-W25", "average_amount": 0 },
          { "week": "2025-W26", "average_amount": 1200 }
        ]
      }
    ]
  }
]
```

**Nota:** Actualmente, el endpoint, no entrega semanas con `average_amount` dado que desde los datos, no hay ninguna semana sin recargas, para cada cliente, pero se ha implementado la l√≥gica para que si existieran semanas sin recargas, se devuelvan con `average_amount` como 0.

---

### ‚úçÔ∏è Parte 2

#### Limitaciones de la soluci√≥n actual

- **Beneficio autom√°tico por 5 visitas seguidas:**
  - La l√≥gica actual procesa todos los eventos en memoria y recorre secuencialmente los eventos de cada cliente y tienda. Esto es eficiente para vol√∫menes peque√±os o medianos, pero puede consumir mucha memoria y tiempo si la cantidad de eventos crece mucho.
  - No se implementa procesamiento incremental ni en tiempo real: si los eventos llegan en streaming o en lotes muy grandes, habr√≠a que adaptar la l√≥gica para evitar reprocesar todo el hist√≥rico cada vez.
  - La deduplicaci√≥n de beneficios depende de la consulta previa a la base de datos, lo que puede ser costoso si hay muchos clientes y beneficios.

- **Historial de transacciones agrupado:**
  - El c√°lculo del historial semanal se hace en memoria, agrupando todos los eventos del cliente y generando el rango de semanas. Si el rango es muy grande y hay muchos clientes, el consumo de memoria puede crecer r√°pidamente.
  - Actualmente, la l√≥gica depende de que los eventos est√©n correctamente fechados y no contempla eventos fuera de rango o inconsistentes.
  - Si el volumen de datos es muy alto, la consulta inicial (`findMany`) puede ser lenta y costosa.

#### Escalabilidad con 100.000 eventos diarios

- **Beneficio autom√°tico por 5 visitas seguidas:**
  - Procesar 100.000 eventos diarios en memoria no es escalable. Se recomienda migrar la l√≥gica a un job batch as√≠ncrono, dividir el procesamiento por cliente o tienda, y/o delegar la detecci√≥n de secuencias a la base de datos usando SQL avanzado (window functions).
  - Para escenarios de alta concurrencia, ser√≠a ideal usar colas de procesamiento y particionar los datos para evitar cuellos de botella.

- **Historial de transacciones agrupado:**
  - Con 100.000 eventos diarios, la consulta y el procesamiento en memoria pueden volverse lentos y consumir demasiados recursos.
  - Para escalar, se recomienda paginar los resultados, limitar el rango de fechas consultado, o precalcular/agregar los datos semanalmente en la base de datos (por ejemplo, usando vistas materializadas o tablas de agregados).
  - Tambi√©n se puede considerar exponer endpoints que permitan filtrar por cliente y rango de fechas para reducir la cantidad de datos procesados en cada consulta.

---

## ‚úÖ Requisitos t√©cnicos

## üìö Decisiones y notas t√©cnicas

### Modelo de datos

He optado por un modelo relacional simple y eficiente para la prueba:

- **clients y stores**: Identifican a los actores principales.
- **events**: Almacena cada acci√≥n (visita o recarga) con su tipo, monto y timestamp, permitiendo consultas eficientes para ambos requerimientos.
- **benefits**: Registra los beneficios otorgados, vinculados a cliente y tienda, con descripci√≥n y fecha.

Las relaciones permiten consultar f√°cilmente el historial de eventos y los beneficios por cliente y tienda.
Este modelo es flexible, escalable y f√°cil de consultar para los dos objetivos principales de la prueba. Adem√°s, permite futuras extensiones (m√°s tipos de eventos, m√°s atributos en beneficios, etc.)

El E/R en DBML:

```SQL
Project ruklo {
  database_type: 'PostgreSQL'
  Note: 'Modelo de datos para la aplicaci√≥n de fidelizaci√≥n Ruklo'
}

// Tabla de Clientes
Table client {
  client_id   varchar   [pk, not null]
  created_at  timestamptz [not null, default: `now()`]
}

// Tabla de Tiendas
Table store {
  store_id    varchar   [pk, not null]
  name        varchar
  created_at  timestamptz [not null, default: `now()`]
}

// Tabla de Eventos (visitas y recargas)
Table event {
  event_id    serial     [not null, increment]
  client_id   varchar    [not null]
  store_id    varchar    [not null]
  type        varchar(10) [not null] // 'visit' o 'recharge'
  amount      int        // solo para 'recharge'
  timestamp   timestamptz [not null]
  primary     key(client_id, store_id) [pk]
}

// Tabla de Beneficios otorgados
Table benefit {
  benefit_id  serial     [pk, not null, increment]
  client_id   varchar    [not null]
  store_id    varchar    [not null]
  description varchar
  granted_at  timestamptz [not null, default: `now()`]
}

// Tabla de relaci√≥n entre Beneficios y Clientes
// Permite que un beneficio pueda ser otorgado a varios clientes
Table benefit_client {
  benefit_id  serial     [not null]
  client_id   varchar    [not null]
  primary     key(client_id, benefit_id) [pk]
}


// Relaciones
Ref: event.client_id > client.client_id // muchos eventos pertenecen a un cliente
Ref: event.store_id > store.store_id // muchos eventos pertenecen a una tienda
Ref: benefit.client_id <> client.client_id // muchos beneficios pertenecen a un cliente
Ref: benefit.store_id > store.store_id // muchos beneficios pertenecen a una tienda
Ref: benefit_client.benefit_id > benefit.benefit_id
Ref: benefit_client.client_id > client.client_id
```

Este E/R tiene una version visualizable en los docs del proyecto:
[Ver modelo E/R (PDF)](./docs/ER-Ruklo-prueba-tecnica.pdf)

### Implementaci√≥n docker-compose para desarrollo

He creado un `docker-compose.yml` para facilitar el desarrollo y pruebas locales para la base de datos
**PostgreSQL**: Base de datos para almacenar los eventos y beneficios.
Esta dockerizaci√≥n permite levantar un entorno de desarrollo completo con un solo comando, facilitando la colaboraci√≥n y pruebas locales.

```bash
docker-compose up -d
```

Tome esta decisi√≥n para asegurar que el entorno de desarrollo sea consistente y f√°cil de configurar, permitiendo a cualquier desarrollador clonar el repositorio y comenzar a trabajar sin complicaciones adicionales.

Luego, es necesario ejecutar las migraciones de Prisma para crear las tablas en la base de datos:

```bash
npx prisma migrate dev
```

### Carga de datos inicial desde el .json a la base de datos

He implementado un script en el backend que carga los datos iniciales desde el archivo `ruklo_events_1000.json` a la base de datos PostgreSQL. Este script se ejecuta al iniciar la aplicaci√≥n, asegurando que los datos de prueba est√©n disponibles para las consultas y pruebas.

**Nota:** Para que el script funcione es necesario ejectuar:

```bash
npx prisma generate
```

Lo que permite generar los clientes de Prisma y as√≠ poder ejecutar el script de carga de datos, con el comando:

```bash
npx ts-node import-events.ts
```

#### Cantidad inicial de entidades

- **Clientes:** 10 (de client_0 a client_9)
- **Tiendas:** 2 (de store_1 a store_2)
- **Eventos:** 1000 (visitas y recargas)

### M√≥dulos de la aplicaci√≥n

La aplicaci√≥n est√° estructurada en m√≥dulos siguiendo las entidades y casos de uso principales:

- **ClientsModule:** Gestiona la informaci√≥n de los clientes y expone endpoints para consultar su historial de eventos y transacciones agrupadas.
- **BenefitsModule:** Encapsula la l√≥gica de detecci√≥n y otorgamiento de beneficios autom√°ticos, as√≠ como la consulta de beneficios por cliente o tienda.
- **StoresModule:** Permite consultar informaci√≥n de tiendas y sus relaciones con clientes y beneficios (opcional, pero recomendado para escalabilidad).
- **EventsModule:** Centraliza la carga, consulta y procesamiento de eventos de visitas y recargas (opcional, √∫til para claridad y futuras extensiones).

Esta modularizaci√≥n permite mantener el c√≥digo organizado, escalable y alineado con las mejores pr√°cticas de NestJS.

### Endpoints implementados

- **GET /benefits/automatic**
  - Detecta y otorga beneficios autom√°ticos por visitas 5 consecutivas sin recarga.
  - Retorna la cantidad de beneficios creados.

Tabla BenefitClient en Prisma studio:

![Prisma Studio](./docs/BenefitClient.png)

Tabla Benefit en Prisma studio:

![Prisma Studio](./docs/Benefit.png)

Tabla Client en Prisma studio:

![Prisma Studio](./docs/Client.png)

Tabla Store en Prisma studio:

![Prisma Studio](./docs/Store.png)

Tabla Event en Prisma studio:

![Prisma Studio](./docs/Event.png)

**Nota:** Son 1000 eventos de prueba cargados desde el archivo `ruklo_events_1000.json`, que incluyen visitas y recargas,
por lo tanto en la foto no se ven todos los eventos.

**Supuesto:** Se asume un cliente no puede tener el mismo beneficio (con el mismo `benefit_id` y `store_id`) m√°s de una vez. Si se detecta un beneficio ya otorgado, no se crea uno nuevo. Pero si el beneficio es diferente (por ejemplo, si se cambia la tienda o la descripci√≥n), se crea un nuevo registro. Por lo tanto, un cliente puede tener m√∫ltiples beneficios diferentes a lo largo del tiempo.

- **GET /clients/transaction-history**
  - Retorna el historial de transacciones de los clientes, agrupado por semana.
  - Incluye visitas y recargas, con totales y conteos por semana.
  
[Ver json resultante del endpoint (JSON)](./docs/history-response.json)
